{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import nltk\n",
    "# Load, explore, process and plot data\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pk\n",
    "\n",
    "#Text Preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blog_url(soup):\n",
    "    div_ = soup.find_all('div', attrs = {'class':'FL PR20'})\n",
    "    url_list = []\n",
    "    for title in div_:\n",
    "        href = title.find('a')['href']\n",
    "        url_list.append(\"https://www.moneycontrol.com/\"+href)\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_blog_content(url):\n",
    "    request = requests.get(url)\n",
    "    print('Received URL',url)\n",
    "    soup = bs4.BeautifulSoup(request.text,'html.parser')\n",
    "    all_script = soup.find_all('script',attrs = {'type':'application/ld+json'})\n",
    "    raw_article_str = all_script[2].get_text().replace('\\r\\n',' ')\n",
    "    parts = re.split(r\"\"\"(\"[^\"]*\"|'[^']*')\"\"\", raw_article_str)\n",
    "    parts[::2] = map(lambda s: \"\".join(s.split()), parts[::2])\n",
    "    article_str = \"\".join(parts)\n",
    "    article_str = article_str[1:]\n",
    "    article_str = article_str[:-1]\n",
    "    article_dict = json.loads(article_str, strict=False)\n",
    "    all_tags = soup.find_all('div',attrs={'class':'tags_first_line'})\n",
    "    list_all_tags=[]\n",
    "    for i in all_tags:\n",
    "        list_all_tags.append(i.get_text())\n",
    "    tags = list_all_tags[0].replace('Tags','')\n",
    "    tags = tags.replace('\\n','')\n",
    "    tags = tags.split('#')\n",
    "    tags = tags[1:]\n",
    "    tags = ', '.join([str(elem).strip() for elem in tags])\n",
    "    article_dict['tags'] = tags\n",
    "    return article_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_no(url, sc_id, page_no, next, year):\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.text,'html.parser')\n",
    "\n",
    "    \n",
    "    all_page_no = soup.find_all('div', attrs = {'class': 'pages MR10 MT15'})\n",
    "    page_list  = [i.text for i in all_page_no[0].find_all('a')]\n",
    "\n",
    "\n",
    "    if any(map(str.isdigit,page_list[-1])):\n",
    "        return int(page_list[-1]), next\n",
    "    else:\n",
    "        next = next + 1\n",
    "        page_no = int(page_list[-2])\n",
    "        url = \"https://www.moneycontrol.com/stocks/company_info/stock_news.php?sc_id=\"+sc_id+\"&scat=&pageno=\"+str(page_no)+\"&next=\"+str(next)+\"&durationType=Y&Year=\"+str(year)+\"&duration=1&news_type=\"\n",
    "    return get_page_no(url, sc_id, page_no, next, year)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_company_data(url_ = \"https://www.moneycontrol.com/stocks/company_info/stock_news.php?\", sc_id=[], pageno=1, next=0, years=[]):\n",
    "    for company in sc_id:\n",
    "        df = pd.DataFrame(columns = ['company', 'datePublished', 'author', 'headline',\n",
    "                                     'description', 'articleBosy','tags','url'])\n",
    "        for year in years:\n",
    "            print('Year: ', year)\n",
    "            print('Page_No:', pageno)\n",
    "            print('Next: ', next)\n",
    "\n",
    "            url = url_ + \"sc_id=\"+company+\"&scat=&pageno=\"+str(pageno)+\"&next=\"+str(next)+\"&durationType=Y&Year=\"+str(year)+\"&duration=1&news_type=\"\n",
    "            print('url: ', url)\n",
    "\n",
    "            max_page_no, max_next = get_page_no(url, company, pageno, next, year)\n",
    "            max_next = max_next + 1\n",
    "            print('Total Page:',max_page_no)\n",
    "            for i in range(max_next):\n",
    "                for j in range((i*10)+1, (i*10)+11):\n",
    "                    if j <= max_page_no:\n",
    "                        url_list = []\n",
    "                        url = url_ + \"sc_id=\"+company+\"&scat=&pageno=\"+str(j)+\"&next=\"+str(i)+\"&durationType=Y&Year=\"+str(year)+\"&duration=1&news_type=\"\n",
    "                        print(url)\n",
    "                        request = requests.get(url)\n",
    "                        soup = BeautifulSoup(request.text, 'html.parser')\n",
    "                        \n",
    "                        url_list = get_blog_url(soup)\n",
    "                        \n",
    "                        frame1 = []\n",
    "\n",
    "                        \n",
    "                        for url in url_list:\n",
    "                            try:\n",
    "                                #print('Blog URL:',url)\n",
    "                                article_dict = get_blog_content(url)\n",
    "\n",
    "                                \n",
    "                                print(company)\n",
    "                                print(article_dict['datePublished'])\n",
    "                                print(article_dict['author'])\n",
    "                                print(article_dict['headline'])\n",
    "                                print(article_dict['description'])\n",
    "                                print(article_dict['articleBody'])\n",
    "                                print(article_dict['tags'])\n",
    "                                print(article_dict['url'])\n",
    "                                print('--------------------------------------------------------')\n",
    "\n",
    "                                article_lst = [[company,\n",
    "                                                 article_dict['datePublished'],\n",
    "                                                 article_dict['author'],\n",
    "                                                 article_dict['headline'],\n",
    "                                                 article_dict['description'],\n",
    "                                                 article_dict['articleBody'],\n",
    "                                                 article_dict['tags'],\n",
    "                                                 url]]\n",
    "                               \n",
    "       \n",
    "                                df = pd.concat([df,pd.DataFrame(article_lst, columns=['company','datePublished','author','headline',\n",
    "                                                                                   'description','articleBody','tags','url'])],axis=0, ignore_index = True)\n",
    "                               \n",
    "\n",
    "                            except:\n",
    "                                \n",
    "                                article_lst = [[company, 'error','error','error','error','error','error',url]]\n",
    "                                \n",
    "     \n",
    "                                df = pd.concat([df,pd.DataFrame(article_lst, columns=['company','datePublished','author','headline',\n",
    "                                                                                   'description','articleBody','tags','url'])],axis=0, ignore_index = True)\n",
    "                               \n",
    "                                continue\n",
    "                           \n",
    "        df.to_csv(company+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_company_data(sc_id=['RI'], years = [2008,2007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('News_Data/RI(2011_2023).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['S. No.', 'company', 'datePublished', 'author', 'headline',\n",
       "       'description', 'tags', 'url', 'articleBody'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df = df.drop(['S. No.'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_sentiments = pd.DataFrame({\n",
    "                        'neg':[],\n",
    "                        'neu':[],\n",
    "                        'pos':[],\n",
    "                        'compound':[]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentence):\n",
    "  sentence = re.sub(r\"n\\'t\", \" not\", sentence)\n",
    "  sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
    "  sentence = re.sub(r\"\\'s\", \" is\", sentence)\n",
    "  sentence = re.sub(r\"\\'d\", \" would\", sentence)\n",
    "  sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n",
    "  sentence = re.sub(r\"\\'t\", \" not\", sentence)\n",
    "  sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n",
    "  sentence = re.sub(r\"\\'m\", \" am\", sentence)\n",
    "  sentence = re.sub(r\"wont\", \"will not\", sentence)\n",
    "  sentence = re.sub(r\"wouldnt\", \"would not\", sentence)\n",
    "  sentence = re.sub(r\"shouldnt\", \"should not\", sentence)\n",
    "  sentence = re.sub(r\"couldnt\", \"could not\", sentence)\n",
    "  sentence = re.sub(r\"cudnt\", \"could not\", sentence)\n",
    "  sentence = re.sub(r\"cant\", \"can not\", sentence)\n",
    "  sentence = re.sub(r\"dont\", \"do not\", sentence)\n",
    "  sentence = re.sub(r\"doesnt\", \"does not\", sentence)\n",
    "  sentence = re.sub(r\"didnt\", \"did not\", sentence)\n",
    "  sentence = re.sub(r\"wasnt\", \"was not\", sentence)\n",
    "  sentence = re.sub(r\"werent\", \"were not\", sentence)\n",
    "  sentence = re.sub(r\"havent\", \"have not\", sentence)\n",
    "  sentence = re.sub(r\"hadnt\", \"had not\", sentence)\n",
    "  sentence = re.sub(r\"ain't\", \"am not\",sentence)\n",
    "  sentence = re.sub(r\"aren't\", \"are not\",sentence)\n",
    "  sentence = re.sub(r\"can't\", \"cannot\",sentence)\n",
    "  sentence = re.sub(r\"can't've\", \"cannot have\",sentence)\n",
    "  sentence = re.sub(r\"'cause\", \"because\",sentence)\n",
    "  sentence = re.sub(r\"could've\", \"could have\",sentence)\n",
    "  sentence = re.sub(r\"couldn't\", \"could not\",sentence)\n",
    "  sentence = re.sub(r\"couldn't've\", \"could not have\",sentence)\n",
    "  sentence = re.sub(r\"didn't\", \"did not\",sentence)\n",
    "  sentence = re.sub(r\"doesn't\", \"does not\",sentence)\n",
    "  sentence = re.sub(r\"don't\", \"do not\",sentence)\n",
    "  sentence = re.sub(r\"hadn't\", \"had not\",sentence)\n",
    "  sentence = re.sub(r\"hadn't've\", \"had not have\",sentence)\n",
    "  sentence = re.sub(r\"hasn't\", \"has not\",sentence)\n",
    "  sentence = re.sub(r\"haven't\", \"have not\",sentence)\n",
    "  sentence = re.sub(r\"he'd\", \"he would\",sentence)\n",
    "  sentence = re.sub(r\"he'd've\", \"he would have\",sentence)\n",
    "  sentence = re.sub(r\"he'll\", \"he will\",sentence)\n",
    "  sentence = re.sub(r\"he'll've\", \"he will have\",sentence)\n",
    "  sentence = re.sub(r\"he's\", \"he is\",sentence)\n",
    "  sentence = re.sub(r\"how'd\", \"how did\",sentence)\n",
    "  sentence = re.sub(r\"how'd'y\", \"how do you\",sentence)\n",
    "  sentence = re.sub(r\"how'll\", \"how will\",sentence)\n",
    "  sentence = re.sub(r\"how's\", \"how is\",sentence)\n",
    "  sentence = re.sub(r\"i'd\", \"I would\",sentence)\n",
    "  sentence = re.sub(r\"i'd've\", \"I would have\",sentence)\n",
    "  sentence = re.sub(r\"i'll\", \"I will\",sentence)\n",
    "  sentence = re.sub(r\"i'll've\", \"I will have\",sentence)\n",
    "  sentence = re.sub(r\"i'm\", \"I am\",sentence)\n",
    "  sentence = re.sub(r\"i've\", \"I have\",sentence)\n",
    "  sentence = re.sub(r\"isn't\", \"is not\",sentence)\n",
    "  sentence = re.sub(r\"it'd\", \"it had\",sentence)\n",
    "  sentence = re.sub(r\"it'd've\", \"it would have\",sentence)\n",
    "  sentence = re.sub(r\"it'll\", \"it will\",sentence)\n",
    "  sentence = re.sub(r\"it'll've\", \"it will have\",sentence)\n",
    "  sentence = re.sub(r\"it's\", \"it is\",sentence)\n",
    "  sentence = re.sub(r\"let's\", \"let us\",sentence)\n",
    "  sentence = re.sub(r\"ma'am\", \"madam\",sentence)\n",
    "  sentence = re.sub(r\"mayn't\", \"may not\",sentence)\n",
    "  sentence = re.sub(r\"might've\", \"might have\",sentence)\n",
    "  sentence = re.sub(r\"mightn't\", \"might not\",sentence)\n",
    "  sentence = re.sub(r\"mightn't've\", \"might not have\",sentence)\n",
    "  sentence = re.sub(r\"must've\", \"must have\",sentence)\n",
    "  sentence = re.sub(r\"mustn't\", \"must not\",sentence)\n",
    "  sentence = re.sub(r\"mustn't've\", \"must not have\",sentence)\n",
    "  sentence = re.sub(r\"needn't\", \"need not\",sentence)\n",
    "  sentence = re.sub(r\"needn't've\", \"need not have\",sentence)\n",
    "  sentence = re.sub(r\"o'clock\", \"of the clock\",sentence)\n",
    "  sentence = re.sub(r\"oughtn't\", \"ought not\",sentence)\n",
    "  sentence = re.sub(r\"oughtn't've\", \"ought not have\",sentence)\n",
    "  sentence = re.sub(r\"shan't\", \"shall not\",sentence)\n",
    "  sentence = re.sub(r\"sha'n't\", \"shall not\",sentence)\n",
    "  sentence = re.sub(r\"shan't've\", \"shall not have\",sentence)\n",
    "  sentence = re.sub(r\"she'd\", \"she would\",sentence)\n",
    "  sentence = re.sub(r\"she'd've\", \"she would have\",sentence)\n",
    "  sentence = re.sub(r\"she'll\", \"she will\",sentence)\n",
    "  sentence = re.sub(r\"she'll've\", \"she will have\",sentence)\n",
    "  sentence = re.sub(r\"she's\", \"she is\",sentence)\n",
    "  sentence = re.sub(r\"should've\", \"should have\",sentence)\n",
    "  sentence = re.sub(r\"shouldn't\", \"should not\",sentence)\n",
    "  sentence = re.sub(r\"shouldn't've\", \"should not have\",sentence)\n",
    "  sentence = re.sub(r\"so've\", \"so have\",sentence)\n",
    "  sentence = re.sub(r\"so's\", \"so is\",sentence)\n",
    "  sentence = re.sub(r\"that'd\", \"that would\",sentence)\n",
    "  sentence = re.sub(r\"that'd've\", \"that would have\",sentence)\n",
    "  sentence = re.sub(r\"that's\", \"that is\",sentence)\n",
    "  sentence = re.sub(r\"there'd\", \"there had\",sentence)\n",
    "  sentence = re.sub(r\"there'd've\", \"there would have\",sentence)\n",
    "  sentence = re.sub(r\"there's\", \"there is\",sentence)\n",
    "  sentence = re.sub(r\"they'd\", \"they would\",sentence)\n",
    "  sentence = re.sub(r\"they'd've\", \"they would have\",sentence)\n",
    "  sentence = re.sub(r\"they'll\", \"they will\",sentence)\n",
    "  sentence = re.sub(r\"they'll've\", \"they will have\",sentence)\n",
    "  sentence = re.sub(r\"they're\", \"they are\",sentence)\n",
    "  sentence = re.sub(r\"they've\", \"they have\",sentence)\n",
    "  sentence = re.sub(r\"to've\", \"to have\",sentence)\n",
    "  sentence = re.sub(r\"wasn't\", \"was not\",sentence)\n",
    "  sentence = re.sub(r\"we'd\", \"we had\",sentence)\n",
    "  sentence = re.sub(r\"we'd've\", \"we would have\",sentence)\n",
    "  sentence = re.sub(r\"we'll\", \"we will\",sentence)\n",
    "  sentence = re.sub(r\"we'll've\", \"we will have\",sentence)\n",
    "  sentence = re.sub(r\"we're\", \"we are\",sentence)\n",
    "  sentence = re.sub(r\"we've\", \"we have\",sentence)\n",
    "  sentence = re.sub(r\"weren't\", \"were not\",sentence)\n",
    "  sentence = re.sub(r\"what'll\", \"what will\",sentence)\n",
    "  sentence = re.sub(r\"what'll've\", \"what will have\",sentence)\n",
    "  sentence = re.sub(r\"what're\", \"what are\",sentence)\n",
    "  sentence = re.sub(r\"what's\", \"what is\",sentence)\n",
    "  sentence = re.sub(r\"what've\", \"what have\",sentence)\n",
    "  sentence = re.sub(r\"when's\", \"when is\",sentence)\n",
    "  sentence = re.sub(r\"when've\", \"when have\",sentence)\n",
    "  sentence = re.sub(r\"where'd\", \"where did\",sentence)\n",
    "  sentence = re.sub(r\"where's\", \"where is\",sentence)\n",
    "  sentence = re.sub(r\"where've\", \"where have\",sentence)\n",
    "  sentence = re.sub(r\"who'll\", \"who will\",sentence)\n",
    "  sentence = re.sub(r\"who'll've\", \"who will have\",sentence)\n",
    "  sentence = re.sub(r\"who's\", \"who is\",sentence)\n",
    "  sentence = re.sub(r\"who've\", \"who have\",sentence)\n",
    "  sentence = re.sub(r\"why's\", \"why is\",sentence)\n",
    "  sentence = re.sub(r\"why've\", \"why have\",sentence)\n",
    "  sentence = re.sub(r\"will've\", \"will have\",sentence)\n",
    "  sentence = re.sub(r\"won't\", \"will not\",sentence)\n",
    "  sentence = re.sub(r\"won't've\", \"will not have\",sentence)\n",
    "  sentence = re.sub(r\"would've\", \"would have\",sentence)\n",
    "  sentence = re.sub(r\"wouldn't\", \"would not\",sentence)\n",
    "  sentence = re.sub(r\"wouldn't've\", \"would not have\",sentence)\n",
    "  sentence = re.sub(r\"y'all\", \"you all\",sentence)\n",
    "  sentence = re.sub(r\"y'alls\", \"you alls\",sentence)\n",
    "  sentence = re.sub(r\"y'all'd\", \"you all would\",sentence)\n",
    "  sentence = re.sub(r\"y'all'd've\", \"you all would have\",sentence)\n",
    "  sentence = re.sub(r\"y'all're\", \"you all are\",sentence)\n",
    "  sentence = re.sub(r\"y'all've\", \"you all have\",sentence)\n",
    "  sentence = re.sub(r\"you'd\", \"you had\",sentence)\n",
    "  sentence = re.sub(r\"you'd've\", \"you would have\",sentence)\n",
    "  sentence = re.sub(r\"you'll\", \"you you will\",sentence)\n",
    "  sentence = re.sub(r\"you'll've\", \"you you will have\",sentence)\n",
    "  sentence = re.sub(r\"you're\", \"you are\",sentence)\n",
    "  sentence = re.sub(r\"you've\", \"you have\",sentence)\n",
    "\n",
    "  \n",
    "  sentence = re.sub(r'[^\\w\\s]','',sentence) # Remove Punctutation\n",
    "  \n",
    "  sentence = sentence.lower() # Lower case\n",
    "  \n",
    "  CLEANR = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "  sentence = re.sub(CLEANR, '', sentence)# Remove HTML\n",
    "  \n",
    "  sentence = re.sub('[^A-Za-z]',' ',sentence)# Remove Digits\n",
    " \n",
    "  sentence = re.sub(r'[\\w._%+-]{1,20}@[\\w.-]{1,20}.[A-Za-z]{2,3}','', sentence)# Remove Email\n",
    "  \n",
    "  sentence = re.sub(r'^http?s:\\/\\/.*[\\r\\n]*','', sentence)# Remove URLs\n",
    "  \n",
    "  sentence = re.sub(r'@[A-Za-z0-9]+','',sentence) #Remove Mentions  \n",
    "\n",
    "  sentence = \" \".join(item for item in sentence.split() if item not in stopwords.words('english') )\n",
    "  \n",
    "  sentence = ' '.join([PorterStemmer().stem(word)for word in sentence.split()])\n",
    "\n",
    "  sentence = ' '.join([WordNetLemmatizer().lemmatize(word) for word in sentence.split()])\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "for text in df.articleBody:\n",
    "    preprocessedText = preprocessing(text)\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    polarity = sid.polarity_scores(str(preprocessedText))    \n",
    "    tmpdic = {}    \n",
    "    tmpdic.update(polarity)\n",
    "    article_sentiments= pd.concat([article_sentiments,pd.DataFrame([tmpdic])], ignore_index=True)    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.9382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.9382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.074</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4576</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.9853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4577</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.9887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>0.132</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.9468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579</th>\n",
       "      <td>0.053</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.9935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.9844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4581 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        neg    neu    pos  compound\n",
       "0     0.000  0.925  0.075    0.6124\n",
       "1     0.000  0.925  0.075    0.6124\n",
       "2     0.167  0.797  0.036   -0.9382\n",
       "3     0.167  0.797  0.036   -0.9382\n",
       "4     0.074  0.849  0.077    0.0258\n",
       "...     ...    ...    ...       ...\n",
       "4576  0.000  0.807  0.193    0.9853\n",
       "4577  0.000  0.795  0.205    0.9887\n",
       "4578  0.132  0.831  0.037   -0.9468\n",
       "4579  0.053  0.803  0.144    0.9935\n",
       "4580  0.040  0.840  0.120    0.9844\n",
       "\n",
       "[4581 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save DataFrame \n",
    "\n",
    "article_sentiments.to_pickle(\"News_Data/article_sentiments_RI_2011_2023.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_sentiments.to_csv(\"News_Data/article_sentiments_RI_2011-2023.csv\", sep=',', encoding='utf-8', header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.9382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.9382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.074</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4576</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.9853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4577</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.9887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>0.132</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.9468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579</th>\n",
       "      <td>0.053</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.9935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.9844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4581 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        neg    neu    pos  compound\n",
       "0     0.000  0.925  0.075    0.6124\n",
       "1     0.000  0.925  0.075    0.6124\n",
       "2     0.167  0.797  0.036   -0.9382\n",
       "3     0.167  0.797  0.036   -0.9382\n",
       "4     0.074  0.849  0.077    0.0258\n",
       "...     ...    ...    ...       ...\n",
       "4576  0.000  0.807  0.193    0.9853\n",
       "4577  0.000  0.795  0.205    0.9887\n",
       "4578  0.132  0.831  0.037   -0.9468\n",
       "4579  0.053  0.803  0.144    0.9935\n",
       "4580  0.040  0.840  0.120    0.9844\n",
       "\n",
       "[4581 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_sentiments_RI_2011_2023 = pd.read_csv('News_Data/article_sentiments_RI_2011-2023.csv')\n",
    "article_sentiments_RI_2011_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_merge_sentiment_score = df.merge(article_sentiments_RI_2011_2023, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>datePublished</th>\n",
       "      <th>author</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>url</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RI</td>\n",
       "      <td>2011-01-03T13:19:20+05:30</td>\n",
       "      <td>{'@type': 'Person', 'name': 'webtech_news18'}</td>\n",
       "      <td>RIL commissions biz transformation plans for F...</td>\n",
       "      <td>Reliance Industries (RIL) has commissioned bus...</td>\n",
       "      <td>BP, Business, E&amp;P, exploration, Jamnagar, oil,...</td>\n",
       "      <td>https://www.moneycontrol.com//news/business/ri...</td>\n",
       "      <td>Reliance Industries (RIL) has commissioned bus...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RI</td>\n",
       "      <td>2011-01-03T13:19:20+05:30</td>\n",
       "      <td>{'@type': 'Person', 'name': 'webtech_news18'}</td>\n",
       "      <td>RIL commissions biz transformation plans for F...</td>\n",
       "      <td>Reliance Industries (RIL) has commissioned bus...</td>\n",
       "      <td>BP, Business, E&amp;P, exploration, Jamnagar, oil,...</td>\n",
       "      <td>https://www.moneycontrol.com//news/business/ri...</td>\n",
       "      <td>Reliance Industries (RIL) has commissioned bus...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RI</td>\n",
       "      <td>2011-01-11T15:24:12+05:30</td>\n",
       "      <td>{'@type': 'Person', 'name': 'webtech_news18'}</td>\n",
       "      <td>Reliance Industries D6 block capacity falls to...</td>\n",
       "      <td>Reliance Industries has a current gas output c...</td>\n",
       "      <td>Business, D6 block, India's upstream regulator...</td>\n",
       "      <td>https://www.moneycontrol.com//news/business/re...</td>\n",
       "      <td>Reliance Industries has a current gas output c...</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.9382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RI</td>\n",
       "      <td>2011-01-11T15:24:12+05:30</td>\n",
       "      <td>{'@type': 'Person', 'name': 'webtech_news18'}</td>\n",
       "      <td>Reliance Industries D6 block capacity falls to...</td>\n",
       "      <td>Reliance Industries has a current gas output c...</td>\n",
       "      <td>Business, D6 block, India's upstream regulator...</td>\n",
       "      <td>https://www.moneycontrol.com//news/business/re...</td>\n",
       "      <td>Reliance Industries has a current gas output c...</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.9382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RI</td>\n",
       "      <td>2011-01-13T13:37:17+05:30</td>\n",
       "      <td>{'@type': 'Person', 'name': 'Rakesh Patil'}</td>\n",
       "      <td>RIL Dec qtr PAT seen up 38% at Rs 5535cr: Angel</td>\n",
       "      <td>Angel Broking has come out with its earning es...</td>\n",
       "      <td>Angel Broking, Brokerage Results Estimates, RIL</td>\n",
       "      <td>https://www.moneycontrol.com//news/brokerage-r...</td>\n",
       "      <td>Angel Broking has come out with its earning es...</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4576</th>\n",
       "      <td>RI</td>\n",
       "      <td>2023-04-21T23:11:20+05:30</td>\n",
       "      <td>{'@type': 'Person', 'name': 'Abhishek Shingare'}</td>\n",
       "      <td>Reliance Standalone March 2023 Net Sales at Rs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Earnings First-Cut, Refineries, Reliance, Reli...</td>\n",
       "      <td>https://www.moneycontrol.com//news/results/rel...</td>\n",
       "      <td>Reported Standalone quarterly numbers for Reli...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.9853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4577</th>\n",
       "      <td>RI</td>\n",
       "      <td>2023-04-21T23:11:26+05:30</td>\n",
       "      <td>{'@type': 'Person', 'name': 'Abhishek Shingare'}</td>\n",
       "      <td>Reliance Consolidated March 2023 Net Sales at ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Earnings First-Cut, Refineries, Reliance, Reli...</td>\n",
       "      <td>https://www.moneycontrol.com//news/results/rel...</td>\n",
       "      <td>Reported Consolidated quarterly numbers for Re...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.9887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>RI</td>\n",
       "      <td>2023-04-22T14:43:55+05:30</td>\n",
       "      <td>{'@type': 'Person', 'url': 'https://www.moneyc...</td>\n",
       "      <td>Reliance Industries monitoring OPEC+ supply cu...</td>\n",
       "      <td>Reliance Industries on April 21 reported 19.1 ...</td>\n",
       "      <td>Crude oil, oil demand, Reliance Industries, Re...</td>\n",
       "      <td>https://www.moneycontrol.com//news/results/rel...</td>\n",
       "      <td>The recent oil production cut announced by the...</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.9468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579</th>\n",
       "      <td>RI</td>\n",
       "      <td>2023-04-24T08:26:37+05:30</td>\n",
       "      <td>{'@type': 'Person', 'url': 'https://www.moneyc...</td>\n",
       "      <td>Reliance Industries Q4 earnings beat estimates...</td>\n",
       "      <td>Reliance Industries Q4 result: Gross revenue f...</td>\n",
       "      <td>Buzzing Stocks, Reliance Industries</td>\n",
       "      <td>https://www.moneycontrol.com//news/buzzing-sto...</td>\n",
       "      <td>Reliance Industries will drive investors' atte...</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.9935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>RI</td>\n",
       "      <td>2023-05-01T09:15:50+05:30</td>\n",
       "      <td>{'@type': 'Person', 'url': 'https://www.moneyc...</td>\n",
       "      <td>Interview | Bullish on PSU pack, bet on REC  ...</td>\n",
       "      <td>Nifty, which has started a structure of higher...</td>\n",
       "      <td>MARKET OUTLOOK, Nifty, Santosh Meena, Sensex</td>\n",
       "      <td>https://www.moneycontrol.com//news/market-outl...</td>\n",
       "      <td>On last Friday, the Nifty PSE index hit a fres...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.9844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4581 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     company              datePublished   \n",
       "0         RI  2011-01-03T13:19:20+05:30  \\\n",
       "1         RI  2011-01-03T13:19:20+05:30   \n",
       "2         RI  2011-01-11T15:24:12+05:30   \n",
       "3         RI  2011-01-11T15:24:12+05:30   \n",
       "4         RI  2011-01-13T13:37:17+05:30   \n",
       "...      ...                        ...   \n",
       "4576      RI  2023-04-21T23:11:20+05:30   \n",
       "4577      RI  2023-04-21T23:11:26+05:30   \n",
       "4578      RI  2023-04-22T14:43:55+05:30   \n",
       "4579      RI  2023-04-24T08:26:37+05:30   \n",
       "4580      RI  2023-05-01T09:15:50+05:30   \n",
       "\n",
       "                                                 author   \n",
       "0         {'@type': 'Person', 'name': 'webtech_news18'}  \\\n",
       "1         {'@type': 'Person', 'name': 'webtech_news18'}   \n",
       "2         {'@type': 'Person', 'name': 'webtech_news18'}   \n",
       "3         {'@type': 'Person', 'name': 'webtech_news18'}   \n",
       "4           {'@type': 'Person', 'name': 'Rakesh Patil'}   \n",
       "...                                                 ...   \n",
       "4576   {'@type': 'Person', 'name': 'Abhishek Shingare'}   \n",
       "4577   {'@type': 'Person', 'name': 'Abhishek Shingare'}   \n",
       "4578  {'@type': 'Person', 'url': 'https://www.moneyc...   \n",
       "4579  {'@type': 'Person', 'url': 'https://www.moneyc...   \n",
       "4580  {'@type': 'Person', 'url': 'https://www.moneyc...   \n",
       "\n",
       "                                               headline   \n",
       "0     RIL commissions biz transformation plans for F...  \\\n",
       "1     RIL commissions biz transformation plans for F...   \n",
       "2     Reliance Industries D6 block capacity falls to...   \n",
       "3     Reliance Industries D6 block capacity falls to...   \n",
       "4       RIL Dec qtr PAT seen up 38% at Rs 5535cr: Angel   \n",
       "...                                                 ...   \n",
       "4576  Reliance Standalone March 2023 Net Sales at Rs...   \n",
       "4577  Reliance Consolidated March 2023 Net Sales at ...   \n",
       "4578  Reliance Industries monitoring OPEC+ supply cu...   \n",
       "4579  Reliance Industries Q4 earnings beat estimates...   \n",
       "4580   Interview | Bullish on PSU pack, bet on REC  ...   \n",
       "\n",
       "                                            description   \n",
       "0     Reliance Industries (RIL) has commissioned bus...  \\\n",
       "1     Reliance Industries (RIL) has commissioned bus...   \n",
       "2     Reliance Industries has a current gas output c...   \n",
       "3     Reliance Industries has a current gas output c...   \n",
       "4     Angel Broking has come out with its earning es...   \n",
       "...                                                 ...   \n",
       "4576                                                NaN   \n",
       "4577                                                NaN   \n",
       "4578  Reliance Industries on April 21 reported 19.1 ...   \n",
       "4579  Reliance Industries Q4 result: Gross revenue f...   \n",
       "4580  Nifty, which has started a structure of higher...   \n",
       "\n",
       "                                                   tags   \n",
       "0     BP, Business, E&P, exploration, Jamnagar, oil,...  \\\n",
       "1     BP, Business, E&P, exploration, Jamnagar, oil,...   \n",
       "2     Business, D6 block, India's upstream regulator...   \n",
       "3     Business, D6 block, India's upstream regulator...   \n",
       "4       Angel Broking, Brokerage Results Estimates, RIL   \n",
       "...                                                 ...   \n",
       "4576  Earnings First-Cut, Refineries, Reliance, Reli...   \n",
       "4577  Earnings First-Cut, Refineries, Reliance, Reli...   \n",
       "4578  Crude oil, oil demand, Reliance Industries, Re...   \n",
       "4579                Buzzing Stocks, Reliance Industries   \n",
       "4580       MARKET OUTLOOK, Nifty, Santosh Meena, Sensex   \n",
       "\n",
       "                                                    url   \n",
       "0     https://www.moneycontrol.com//news/business/ri...  \\\n",
       "1     https://www.moneycontrol.com//news/business/ri...   \n",
       "2     https://www.moneycontrol.com//news/business/re...   \n",
       "3     https://www.moneycontrol.com//news/business/re...   \n",
       "4     https://www.moneycontrol.com//news/brokerage-r...   \n",
       "...                                                 ...   \n",
       "4576  https://www.moneycontrol.com//news/results/rel...   \n",
       "4577  https://www.moneycontrol.com//news/results/rel...   \n",
       "4578  https://www.moneycontrol.com//news/results/rel...   \n",
       "4579  https://www.moneycontrol.com//news/buzzing-sto...   \n",
       "4580  https://www.moneycontrol.com//news/market-outl...   \n",
       "\n",
       "                                            articleBody    neg    neu    pos   \n",
       "0     Reliance Industries (RIL) has commissioned bus...  0.000  0.925  0.075  \\\n",
       "1     Reliance Industries (RIL) has commissioned bus...  0.000  0.925  0.075   \n",
       "2     Reliance Industries has a current gas output c...  0.167  0.797  0.036   \n",
       "3     Reliance Industries has a current gas output c...  0.167  0.797  0.036   \n",
       "4     Angel Broking has come out with its earning es...  0.074  0.849  0.077   \n",
       "...                                                 ...    ...    ...    ...   \n",
       "4576  Reported Standalone quarterly numbers for Reli...  0.000  0.807  0.193   \n",
       "4577  Reported Consolidated quarterly numbers for Re...  0.000  0.795  0.205   \n",
       "4578  The recent oil production cut announced by the...  0.132  0.831  0.037   \n",
       "4579  Reliance Industries will drive investors' atte...  0.053  0.803  0.144   \n",
       "4580  On last Friday, the Nifty PSE index hit a fres...  0.040  0.840  0.120   \n",
       "\n",
       "      compound  \n",
       "0       0.6124  \n",
       "1       0.6124  \n",
       "2      -0.9382  \n",
       "3      -0.9382  \n",
       "4       0.0258  \n",
       "...        ...  \n",
       "4576    0.9853  \n",
       "4577    0.9887  \n",
       "4578   -0.9468  \n",
       "4579    0.9935  \n",
       "4580    0.9844  \n",
       "\n",
       "[4581 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_merge_sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_merge_sentiment_score.to_csv(\"News_Data/RI(2011_2023)_articleBody_Sentiment_Score.csv\", sep=',', encoding='utf-8', header=True,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
